# -*- coding: utf-8-sig -*-
import json
import os
import regex
import gradio as gr
import openai
import requests
from utils.chatgpt_utils import *
from utils.regex_utils import *
import api.context_type as ContextType
from api.base_api import *
from utils.chatgpt_utils import process_context,process_chat


# è¨­ç½®æ‚¨çš„OpenAI APIé‡‘é‘°
#è«‹å°‡æ‚¨çš„é‡‘é‘°å€¼å¯«å…¥è‡³ç’°å¢ƒè®Šæ•¸"OPENAI_API_KEY"ä¸­
#os.environ['OPENAI_API_KEY']=#'ä½ çš„é‡‘é‘°å€¼'
if "OPENAI_API_KEY" not in os.environ:
    print("OPENAI_API_KEY  is not exists!")
openai.api_key = os.getenv("OPENAI_API_KEY")
URL = "https://api.openai.com/v1/chat/completions"

baseChatGpt=GptBaseApi(model="gpt-3.5-turbo")

pattern = regex.compile(r'\{(?:[^{}]|(?R))*\}')
def index2context(idx:int):
    if idx is None or idx==0:
        return ContextType.prompt
    elif idx==1:
        return ContextType.globals
    elif idx == 2:
        return ContextType.skip
    elif idx == 3:
        return ContextType.sandbox
    elif idx == 4:
        return ContextType.explain
    elif idx == 5:
        return ContextType.override
    else:
        return '[@PROMPT]'

def prompt_api(inputs, context_type, top_p, temperature, top_k, frequency_penalty, full_history=[]):
    _context_type=index2context(context_type)
    baseChatGpt.API_PARAMETERS['temperature']=temperature
    baseChatGpt.API_PARAMETERS['top_p'] = top_p
    baseChatGpt.API_PARAMETERS['top_k'] = top_k
    baseChatGpt.API_PARAMETERS['frequency_penalty'] = frequency_penalty
    streaming_chat = baseChatGpt.post_a_streaming_chat(inputs, _context_type, baseChatGpt.API_PARAMETERS,baseChatGpt.FULL_HISTORY)
    while True:
        try:
            chat, answer, full_history= next(streaming_chat)
            yield chat,full_history,full_history
        except StopIteration:
            break



def nlu_api(text_input):
    # å‰µå»ºèˆ‡APIçš„å°è©±

    text_inputs=text_input.split('\n')
    _parameters = copy.deepcopy(baseChatGpt.API_PARAMETERS)
    _parameters['temperature'] = 0.1
    results=[]
    for txt in text_inputs:
        conversation = [
            {
                "role": "system",
                "content": "è«‹é€ä¸€è®€å–ä¸‹åˆ—å¥å­ï¼Œæ¯å€‹å¥å­å…ˆç†è§£èªæ„å¾Œå†é€²è¡Œåˆ†è©ã€æƒ…æ„Ÿåµæ¸¬ã€å‘½åå¯¦é«”åµæ¸¬ä»¥åŠæ„åœ–åµæ¸¬ã€‚åˆ†è©çµæœæ˜¯æŒ‡å°‡è¼¸å…¥çš„æ–‡å­—ï¼Œå…ˆé€²è¡Œèªæ„ç†è§£ï¼Œç„¶å¾ŒåŸºæ–¼èªæ„ç†è§£åˆç†æ€§çš„å‰æä¸‹ï¼Œå°‡è¼¸å…¥æ–‡å­—é€²è¡Œåˆ†è©(tokenize)ï¼Œè‹¥éå¿…è¦ï¼Œç›¡é‡ä¸è¦å‡ºç¾è¶…é3å€‹å­—çš„è©ï¼Œç„¶å¾Œä½¿ç”¨ã€Œ|ã€æ’å…¥è‡³åˆ†è©è©å½™å³æ§‹æˆåˆ†è©çµæœã€‚\néœ€è¦åµæ¸¬çš„æƒ…æ„Ÿé¡å‹\næ­£é¢æƒ…ç·’(positive_emotions):[è‡ªä¿¡,å¿«æ¨‚,é«”è²¼,å¹¸ç¦,ä¿¡ä»»,å–œæ„›,å°Šæ¦®,æœŸå¾…,æ„Ÿå‹•,æ„Ÿè¬,ç†±é–€,ç¨ç‰¹,ç¨±è®š]\nè² é¢æƒ…ç·’(negative_emotions):[å¤±æœ›,å±éšª,å¾Œæ‚”,å†·æ¼ ,æ‡·ç–‘,ææ‡¼,æ‚²å‚·,æ†¤æ€’,æ“”å¿ƒ,ç„¡å¥ˆ,ç…©æ‚¶,è™›å‡,è¨å­,è²¶è²¬,è¼•è¦–]\nç•¶å¥å­ä¸­æœ‰ç¬¦åˆä»¥ä¸Šä»»ä½•æƒ…æ„Ÿç¨®é¡æ™‚ï¼Œè«‹ç›¡å¯èƒ½çš„å°‡ç¬¦åˆçš„ã€Œæƒ…æ„Ÿç¨®é¡ã€åŠå¥å­ä¸­çš„é‚£äº›ã€Œè§¸åŠåˆ°æƒ…æ„Ÿç¨®é¡çš„å…§å®¹ã€æˆå°çš„åˆ—èˆ‰å‡ºä¾†ï¼Œä¸€å€‹å¥å­å¯ä»¥è§¸åŠä¸åªä¸€ç¨®æƒ…æ„Ÿã€‚\néœ€è¦åµæ¸¬çš„å¯¦é«”é¡å‹(entities)[ä¸­æ–‡äººå,ä¸­æ–‡ç¿»è­¯äººå,å¤–èªäººå,åœ°å/åœ°é»,æ™‚é–“,å…¬å¸æ©Ÿæ§‹å/å“ç‰Œå,å•†å“å,å•†å“è¦æ ¼,åŒ–åˆç‰©å/æˆåˆ†å,å…¶ä»–å°ˆæœ‰åè©,é‡‘é¡,å…¶ä»–æ•¸å€¼]\næ­¤å¤–ï¼Œè‹¥æ˜¯å¥å­ä¸­æœ‰åµæ¸¬åˆ°ç¬¦åˆä¸Šè¿°å¯¦é«”é¡å‹æ™‚ï¼Œä¹Ÿè«‹ç›¡å¯èƒ½çš„å°‡ç¬¦åˆçš„ã€Œå¯¦é«”é¡å‹ã€åŠå¥å­ä¸­çš„é‚£äº›ã€Œè§¸åŠåˆ°å¯¦é«”é¡å‹å…§å®¹ï½£æˆå°çš„åˆ—èˆ‰å‡ºä¾†ï¼Œä¸€å€‹å¥å­å¯ä»¥è§¸åŠä¸åªä¸€ç¨®å¯¦é«”é¡å‹ã€‚ç•¶ä½ åµæ¸¬åˆ°å¥å­ä¸­æœ‰è¦æ±‚ä½ ä»£ç‚ºåŸ·è¡ŒæŸå€‹ä»»å‹™æˆ–æ˜¯æŸ¥è©¢æŸè³‡è¨Šçš„æ„åœ–(intents)æ™‚ï¼Œæ ¹æ“šä»¥è‹±æ–‡ã€Œåè©+å‹•è©-ingã€çš„é§å³°å¼å‘½åå½¢å¼ä¾†çµ„æˆæ„åœ–é¡åˆ¥(ä¾‹å¦‚ä½¿ç”¨è€…èªªã€Œè«‹å¹«æˆ‘è¨‚ä»Šå¤©ä¸‹åˆ5é»å»é«˜é›„çš„ç«è»Šç¥¨ã€å…¶æ„åœ–é¡åˆ¥ç‚ºTicketOrdering)ï¼ŒåŠå¥å­ä¸­çš„é‚£äº›ã€Œè§¸åŠåˆ°æ„åœ–é¡åˆ¥çš„å…§å®¹ã€æˆå°çš„åˆ—èˆ‰å‡ºä¾†ï¼Œä¸€å€‹å¥å­å¯ä»¥è§¸åŠä¸åªä¸€ç¨®æ„åœ–ã€‚ä»¥ä¸‹ç‚ºã€Œå¼µå¤§å¸¥çš„äººç”Ÿæ˜¯ä¸€å¼µèŒ¶å‡ ï¼Œä¸Šé¢æ”¾æ»¿äº†æ¯å…·ã€‚è€Œæœ¬èº«å°±æ˜¯æ¯å…·ã€çš„ç¯„ä¾‹è§£æçµæœ\n"
                           "{\nsentence:  \"å¼µå¤§å¸¥çš„äººç”Ÿæ˜¯ä¸€å¼µèŒ¶å‡ ï¼Œä¸Šé¢æ”¾æ»¿äº†æ¯å…·ã€‚è€Œæœ¬èº«å°±æ˜¯æ¯å…·\",\nsegmented_sentence:  \"å¼µå¤§å¸¥|çš„|äººç”Ÿ|æ˜¯|ä¸€|å¼µ|èŒ¶å‡ |ï¼Œ|ä¸Šé¢|æ”¾æ»¿äº†|æ¯å…·|ã€‚|è€Œ|æœ¬èº«|å°±æ˜¯|æ¯å…·\",\npositive_emotions:  [\n0:  {\ntype:  \"ç…©æ‚¶\",\ncontent:  \"æ”¾æ»¿äº†æ¯å…·\"\n} ,\n1:  {\ntype:  \"ç„¡å¥ˆ\",\ncontent:  \"æœ¬èº«å°±æ˜¯æ¯å…·\"\n}\n],\nnegative_emotions:  [\n0:  {\ntype:  \"å¤±æœ›\",\ncontent:  \"ä¸Šé¢æ”¾æ»¿äº†æ¯å…·\"\n} \n],\nentities:  [\n0:  {\ntype:  \"ä¸­æ–‡äººå\",\ncontent:\"å¼µå¤§å¸¥\"\n}\n]\n}\n\ræœ€å¾Œå°‡æ¯å€‹å¥å­çš„è§£æçµæœæ•´åˆæˆå–®ä¸€jsonæ ¼å¼ï¼Œç¸®é€²é‡ç‚º1ã€‚"
            },
            {
                "role": "user",
                "content": txt
            }
        ]
        jstrs=pattern.findall(baseChatGpt.post_and_get_answer(conversation, _parameters))
        jstrs = jstrs[0] if len(jstrs) == 1 else '[' + ', '.join(jstrs) + ']'
        output_json = json.loads(jstrs)
        results.append(json.dumps(output_json, ensure_ascii=False, indent=3))

        yield '[' + ', '.join(results) + ']'


def image_api(text_input):
    # å‰µå»ºèˆ‡APIçš„å°è©±

    _parameters = copy.deepcopy(baseChatGpt.API_PARAMETERS)
    _parameters['temperature'] = 0.9
    _parameters['max_tokens'] = 100
    results=[]
    conversation = [
        {
            "role": "system",
            "content": "ä½ æ˜¯ä¸€å€‹æ‰è¯æ´‹æº¢çš„DALLE-2 æç¤ºç”Ÿæˆå·¥å…·ï¼Œä½ æœƒæ ¹æ“šæ¥ä¸‹ä¾†æä¾›çš„è¦–è¦ºéœ€æ±‚ä»¥åŠé¢¨æ ¼è¨­è¨ˆå‡ºå°æ‡‰çš„åœ–åƒé…ç½®ï¼Œä¸¦ä¸”ç”Ÿæˆå‡ºèƒ½è®“DALLE-2ç•«å‡ºç¬¦åˆéœ€æ±‚çš„åœ–ç‰‡ä¹‹ç°¡çŸ­promptï¼Œç‚ºäº†ç¯€çœå­—æ•¸ï¼Œä¸ä¸€å®šè¦å®Œæ•´çš„å¥å­ï¼Œå¯ä»¥æ˜¯ä¸€é€£ä¸²é—œéµè©ï¼Œç„¡é ˆæ‰“æ‹›äº’ä»¥åŠè‡ªæˆ‘ä»‹ç´¹ï¼Œè«‹ç¢ºä¿åœ–åƒå…·å‚™é«˜è§£æåº¦ä»¥åŠè‰¯å¥½ç•«è³ªï¼Œä¸è¦æœ‰æ–‡å­—å‡ºç¾åœ¨åœ–ä¸­ä»¥åŠè¦èƒ½å¤ å¸å¼•äººé¡çš„ç›®å…‰ï¼Œè«‹ç”¨è‹±èªæ’°å¯«ï¼Œçµ•å°ä¸è¦è¶…é800 characters"
        },
        {
            "role": "user",
            "content": text_input
        }
    ]
    image_prompt=baseChatGpt.post_and_get_answer(conversation, _parameters)
    images_urls=baseChatGpt.generate_images(image_prompt)
    # images_urls=["https://www.digitaltrends.com/wp-content/uploads/2022/10/Variation-on-DALL-E-2-Prompt.jpg?fit=720%2C720&p=1",
    #             "https://www.digitaltrends.com/wp-content/uploads/2022/10/DALL-E-2-Image-on-OpenAI.jpg?p=1",
    #             "https://www.google.com/url?sa=i&url=https%3A%2F%2Ffuturism.com%2Fthe-byte%2Fopenai-dall-e2-realistic-images-descriptions&psig=AOvVaw0gIVytXCfu7fj-5LCPA3dM&ust=1681743982221000&source=images&cd=vfe&ved=0CBEQjRxqFwoTCJiQl9fWrv4CFQAAAAAdAAAAABAQ",
    #             "https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.reddit.com%2Fr%2FPokemonart%2Fcomments%2Fu05cci%2Fthis_was_generated_by_a_text_to_image_ai_dalle2%2F&psig=AOvVaw0gIVytXCfu7fj-5LCPA3dM&ust=1681743982221000&source=images&cd=vfe&ved=0CBEQjRxqFwoTCJiQl9fWrv4CFQAAAAAdAAAAABAY"]
    return image_prompt,images_urls


def clear_history():
    baseChatGpt.FULL_HISTORY=[baseChatGpt.FULL_HISTORY[0]]
    return [],baseChatGpt.FULL_HISTORY

def reset_textbox():
    return gr.update(value='')

def reset_context():
    return gr.update(value="[@PROMPT] ä¸€èˆ¬æŒ‡ä»¤")

def pause_message():
    is_pause=True


if __name__ == '__main__':

    title = """<h1 align="center">ğŸ”¥ğŸ¤–ChatGPT Streaming ğŸš€</h1>"""
    description = ""

    with gr.Blocks(css="""#col_container {width: 80%; margin-left: auto; margin-right: auto;}
                    #chatbot {height: 50%; overflow: auto;}
                    #history_viewer {height: 50%; overflow: auto;}""",theme=gr.themes.Soft(spacing_size="sm", radius_size="none",font=["Microsoft JhengHei UI", "Arial", "sans-serif"])) as demo:
        gr.HTML(title)
        with gr.Tabs():
            with gr.TabItem("å°è©±"):
                with gr.Column(elem_id="col_container"):
                    chatbot = gr.Chatbot(color_map=("orange", "dark gray"),elem_id='chatbot')  # c
                    with gr.Row():
                        radio = gr.Radio(["å‰µæ„", "å¹³è¡¡", "ç²¾ç¢º"], show_label=False,interactive=True)
                        context_type = gr.Dropdown(
                            ["[@PROMPT] ä¸€èˆ¬æŒ‡ä»¤", "[@GLOBAL] å…¨å±€æŒ‡ä»¤", "[@SKIP] è·³è„«ä¸Šæ–‡", "[@SANDBOX] æ²™ç®±éš”çµ•", "[@EXPLAIN] è§£é‡‹ä¸Šæ–‡", "[@OVERRIDE] è¦†å¯«å…¨å±€"],
                            value="[@PROMPT] ä¸€èˆ¬æŒ‡ä»¤",type='index',label="contextè™•ç†", elem_id='context_type',interactive=True)
                        scenario_type = gr.Dropdown(
                            ["(ç„¡)","é›»å­éƒµä»¶", "éƒ¨è½æ ¼æ–‡ç« ","æ³•å¾‹æ–‡ä»¶"],value="(ç„¡)", label="æ‡‰ç”¨å ´æ™¯", elem_id='scenario',interactive=True)
                    with gr.Row():
                        inputs = gr.Textbox(placeholder="ä½ èˆ‡èªè¨€æ¨¡å‹Bertæœ‰ä½•ä¸åŒ?", label="è¼¸å…¥æ–‡å­—å¾ŒæŒ‰enter")  # t
                    with gr.Row():
                        b1 = gr.Button(value='é€å‡º')
                    with gr.Row():
                        b3 = gr.Button(value='ğŸ—‘ï¸')
                        b2 = gr.Button(value='â¸ï¸')
                    state = gr.State([{"role": "system", "content": 'æ‰€æœ‰å…§å®¹ä»¥ç¹é«”ä¸­æ–‡æ›¸å¯«'}])  # s
            with gr.TabItem("æ­·å²"):
                with gr.Column(elem_id="col_container"):
                    history_viewer =gr.JSON(elem_id='history_viewer')
            with gr.TabItem("NLU"):
                with gr.Column(elem_id="col_container"):
                    gr.Markdown("å°‡æ–‡æœ¬è¼¸å…¥åˆ°ä¸‹é¢çš„æ–¹å¡Šä¸­ï¼ŒæŒ‰ä¸‹ã€Œé€å‡ºã€æŒ‰éˆ•å°‡æ–‡æœ¬é€£åŒä¸Šè¿°çš„promptç™¼é€è‡³OpenAI ChatGPT APIï¼Œç„¶å¾Œå°‡è¿”å›çš„JSONé¡¯ç¤ºåœ¨è¦–è¦ºåŒ–ç•Œé¢ä¸Šã€‚")
                    with gr.Row():
                        with gr.Column(scale=1):
                            nlu_inputs = gr.Textbox(lines=6, placeholder="è¼¸å…¥å¥å­...")
                        with gr.Column(scale=2):
                            nlu_output =gr.Text(label="å›å‚³çš„JSONè¦–è¦ºåŒ–",interactive=True,max_lines=40).style(show_copy_button=True)
                    nlu_button = gr.Button("é€å‡º")
            with gr.TabItem("Dall.E2"):
                with gr.Column(variant="panel"):
                    with gr.Row(variant="compact"):
                        image_text = gr.Textbox(
                            label="è«‹è¼¸å…¥ä¸­æ–‡çš„æè¿°",
                            show_label=False,
                            max_lines=1,
                            placeholder="è«‹è¼¸å…¥ä¸­æ–‡çš„æè¿°",
                        ).style(
                            container=False,
                        )
                    image_btn = gr.Button("è¨­è¨ˆèˆ‡ç”Ÿæˆåœ–ç‰‡").style(full_width=False)
                    image_prompt=gr.Markdown("")
                    image_gallery = gr.Gallery(value=None,show_label=False).style(grid=4)


            # with gr.TabItem("ç¿»è­¯"):
            #     with gr.Column(elem_id="col_container"):
            #         history_viewer = gr.Text(elem_id='history_viewer',max_lines=30)
        # inputs, top_p, temperature, top_k, repetition_penalty
        with gr.Accordion("è¶…åƒæ•¸", open=False):
            top_p = gr.Slider(minimum=-0, maximum=1.0, value=0.95, step=0.05, interactive=True,
                              label="é™åˆ¶å–æ¨£ç¯„åœ(Top-p)", )
            temperature = gr.Slider(minimum=-0, maximum=5.0, value=1, step=0.1, interactive=True,
                                    label="æº«åº¦ (Temperature)", )
            top_k = gr.Slider(minimum=1, maximum=50, value=1, step=1, interactive=True, label="å€™é¸çµæœå€‹æ•¸(Top-k)", )
            frequency_penalty = gr.Slider(minimum=-2, maximum=2, value=0, step=0.01, interactive=True,
                                          label="é‡è¤‡æ€§è™•ç½°(Frequency Penalty)",
                                          info='å€¼åŸŸç‚º-2~+2ï¼Œæ•¸å€¼è¶Šå¤§ï¼Œå°æ–¼é‡è¤‡ç”¨å­—æœƒçµ¦äºˆæ‡²ç½°ï¼Œæ•¸å€¼è¶Šè² ï¼Œå‰‡é¼“å‹µé‡è¤‡ç”¨å­—')



        inputs.submit(prompt_api, [inputs, context_type, top_p, temperature, top_k, frequency_penalty, state],
                      [chatbot, state,history_viewer]).then(reset_context, [], [context_type]).then(reset_textbox, [], [inputs])
        b1.click(prompt_api, [inputs, context_type, top_p, temperature, top_k, frequency_penalty, state], [chatbot, state,history_viewer], )
        b3.click(clear_history, [], [chatbot,history_viewer]).then(reset_textbox, [], [inputs])
        b2.click(fn=pause_message, inputs=[], outputs=None)


        nlu_inputs.submit(nlu_api, nlu_inputs,nlu_output)
        nlu_button.click(nlu_api, nlu_inputs, nlu_output)

        image_text.submit(image_api, image_text,[image_prompt,image_gallery])
        image_btn.click(image_api, image_text, [image_prompt,image_gallery])

        gr.Markdown(description)
        demo.queue(concurrency_count=3,api_open=True).launch(show_error=True)
